{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9abf9df-2def-4056-9fdb-7cd50c5388af",
   "metadata": {},
   "source": [
    "### Importing and setting up the client to interact with carla server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bf7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc6283-b8b2-4b54-b935-7f6a9f948a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4089226510.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    img_2 =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Call back function to capture and save image\n",
    "def process_image(image):\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image.raw_data)\n",
    "    image_array = image_array.reshape((image.height, image.width, 4))\n",
    "    image_array = image_array[:, :, :3]\n",
    "    cv2.imwrite('/home/mudit/independent_study/cam_cap/camera0_image' + str(time.time()) + '.png', image_array)\n",
    "\n",
    "def segment_callback(image):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    img_2 = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img_2 = img_2[:, :, :3]\n",
    "    cv2.imwrite('sem_seg/semantic_seg_img_' + str(time.time()) + '.png', img_2)\n",
    "\n",
    "# Callback stores sensor data in a dictionary for use outside callback                         \n",
    "def seg_camera_callback(image, data_dict):\n",
    "#     image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    img_2 = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img_2 = img_2[:, :, :3]\n",
    "    img_2 = \n",
    "    print(img_2.min())\n",
    "    print(img_2.max())\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6965da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c603714",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_library = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d602c-0870-4fc7-a0ca-7112700e5fbe",
   "metadata": {},
   "source": [
    "### Spawnning a vehicle and setting spectator camera at appropriate position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "637becc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_init_transform = carla.Transform(carla.Location(x=1.0, y=0.0, z=200.4), carla.Rotation(pitch=-90.0, yaw=0.0, roll=0.0))\n",
    "spectator = world.get_spectator()\n",
    "spectator.set_transform(spec_init_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0954df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_bp = bp_library.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769cc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator = world.get_spectator()\n",
    "veh_transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4, z=2)),vehicle.get_transform().rotation)\n",
    "spectator.set_transform(veh_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6edf648-cde1-4477-a6d8-eb1d5100e622",
   "metadata": {},
   "source": [
    "### Spawn NPC vehicles and set autopilot to true to make them move autonomously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3bb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn dummy vehicles in the world that act as per the carla sim autopilot\n",
    "for i in range(15):\n",
    "    vehicle_bp = random.choice(bp_library.filter('vehicle'))\n",
    "    npc_veh = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    npc_veh.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7cdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set behaviour of the vehicles in the simulation to autopilot of carla sim\n",
    "for veh in world.get_actors().filter('*vehicle*'):\n",
    "\tveh.set_autopilot(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc3726-fa27-483a-911c-3b009dac0afd",
   "metadata": {},
   "source": [
    "### RGB camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2c2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_bp = bp_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '1920')\n",
    "camera_bp.set_attribute('image_size_y', '1080')\n",
    "camera_bp.set_attribute('fov', '110')\n",
    "\n",
    "# Set the time in seconds between sensor captures\n",
    "camera_bp.set_attribute('sensor_tick', '1.0')\n",
    "\n",
    "camera_init_transform = carla.Transform(carla.Location(x=1.0, y=0.0, z=1.4), carla.Rotation(pitch=0.0, yaw=0.0, roll=0.0))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_transform, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b29bbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607ecac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.listen(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a01742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()\n",
    "camera.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073a2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "271f6f98-2934-42b6-a7d7-9c922f154b79",
   "metadata": {},
   "source": [
    "### Semantic segmentation camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df50b4b6-91b1-4e25-ab02-2ce004120bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_camera_bp = bp_library.find('sensor.camera.semantic_segmentation')\n",
    "seg_camera_bp.set_attribute('image_size_x', '1280')\n",
    "seg_camera_bp.set_attribute('image_size_y', '720')\n",
    "seg_camera_bp.set_attribute('fov', '110')\n",
    "\n",
    "# Set the time in seconds between sensor captures\n",
    "seg_camera_bp.set_attribute('sensor_tick', '1.0')\n",
    "\n",
    "seg_camera_init_transform = carla.Transform(carla.Location(x=1.0, y=0.0, z=30), carla.Rotation(pitch=-90.0, yaw=0.0, roll=0.0))\n",
    "seg_camera = world.spawn_actor(seg_camera_bp, seg_camera_init_transform, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc704296",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_camera.listen(segment_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "259fab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "# Get ccamera dimensions and initialise dictionary                       \n",
    "image_w = seg_camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = seg_camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "seg_camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "# Start camera recording\n",
    "seg_camera.listen(lambda image: seg_camera_callback(image, seg_camera_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8815f702",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n",
      "0\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "# OpenCV named window for rendering\n",
    "cv2.namedWindow('segm Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('segm Camera', seg_camera_data['image'])\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Game loop\n",
    "while True:\n",
    "    \n",
    "    # Imshow renders sensor data to display\n",
    "    cv2.imshow('segm Camera', seg_camera_data['image'])\n",
    "    \n",
    "    # Quit if user presses 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close OpenCV window when finished\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4e634b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_camera.stop()\n",
    "seg_camera.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc6a24-b925-4747-a36f-0271ae100fc9",
   "metadata": {},
   "source": [
    "### Lidar data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5a92f1-05d3-4040-a033-56d21c0e75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a588326a-455e-444f-a801-b386ac89542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary code for colormaps and axes\n",
    "VIRIDIS = np.array(cm.get_cmap('plasma').colors)\n",
    "VID_RANGE = np.linspace(0.0, 1.0, VIRIDIS.shape[0])\n",
    "\n",
    "COOL_RANGE = np.linspace(0.0, 1.0, VIRIDIS.shape[0])\n",
    "COOL = np.array(cm.get_cmap('winter')(COOL_RANGE))\n",
    "COOL = COOL[:,:3]\n",
    "\n",
    "def add_open3d_axis(vis):\n",
    "    \"\"\"Add a small 3D axis on Open3D Visualizer\"\"\"\n",
    "    axis = o3d.geometry.LineSet()\n",
    "    axis.points = o3d.utility.Vector3dVector(np.array([\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]]))\n",
    "    axis.lines = o3d.utility.Vector2iVector(np.array([\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [0, 3]]))\n",
    "    axis.colors = o3d.utility.Vector3dVector(np.array([\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]]))\n",
    "    vis.add_geometry(axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bcb7877-749c-4682-854c-819a31042368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIDAR callback\n",
    "def lidar_callback(point_cloud, point_list):\n",
    "    \"\"\"Prepares a point cloud with intensity\n",
    "    colors ready to be consumed by Open3D\"\"\"\n",
    "    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))\n",
    "    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n",
    "\n",
    "    # Isolate the intensity and compute a color for it\n",
    "    intensity = data[:, -1]\n",
    "    intensity_col = 1.0 - np.log(intensity) / np.log(np.exp(-0.004 * 100))\n",
    "    int_color = np.c_[\n",
    "        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 0]),\n",
    "        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 1]),\n",
    "        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 2])]\n",
    "\n",
    "    points = data[:, :-1]\n",
    "\n",
    "    points[:, :1] = -points[:, :1]\n",
    "\n",
    "    point_list.points = o3d.utility.Vector3dVector(points)\n",
    "    point_list.colors = o3d.utility.Vector3dVector(int_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42f022b3-7d5d-4d65-9f13-ab45338fce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LIDAR parameters are to assisst visualisation\n",
    "lidar_bp = bp_library.find('sensor.lidar.ray_cast') \n",
    "lidar_bp.set_attribute('range', '20.0')\n",
    "lidar_bp.set_attribute('noise_stddev', '0.1')\n",
    "lidar_bp.set_attribute('upper_fov', '15.0')\n",
    "lidar_bp.set_attribute('lower_fov', '-15.0')\n",
    "lidar_bp.set_attribute('channels', '64.0')\n",
    "lidar_bp.set_attribute('rotation_frequency', '20.0')\n",
    "lidar_bp.set_attribute('points_per_second', '500000')\n",
    "    \n",
    "lidar_init_trans = carla.Transform(carla.Location(z=2))\n",
    "lidar = world.spawn_actor(lidar_bp, lidar_init_trans, attach_to=vehicle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef5a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add auxilliary data structures\n",
    "point_list = o3d.geometry.PointCloud()\n",
    "\n",
    "# Start sensors\n",
    "lidar.listen(lambda data: lidar_callback(data, point_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open3D visualiser for LIDAR\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(\n",
    "    window_name='Carla Lidar',\n",
    "    width=960,\n",
    "    height=540,\n",
    "    left=480,\n",
    "    top=270)\n",
    "\n",
    "vis.get_render_option().background_color = [0.05, 0.05, 0.05]\n",
    "vis.get_render_option().point_size = 1\n",
    "vis.get_render_option().show_coordinate_frame = True\n",
    "add_open3d_axis(vis)\n",
    "\n",
    "# Update geometry and camera in game loop\n",
    "frame = 0\n",
    "while frame < 10000S:\n",
    "    if frame == 2:\n",
    "        vis.add_geometry(point_list)\n",
    "    vis.update_geometry(point_list)\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    # # This can fix Open3D jittering issues:\n",
    "    time.sleep(0.005)\n",
    "    frame += 1\n",
    "\n",
    "\n",
    "# Close displayws and stop sensors\n",
    "lidar.stop()\n",
    "lidar.destroy()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac61bc",
   "metadata": {},
   "source": [
    "### Remove spawned vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for veh in world.get_actors().filter('*vehicle*'):\n",
    "\tveh.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec5d688",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'disconnect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Disconnect the client from the carla sim server to cleanly exit simulation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m camera\u001b[38;5;241m.\u001b[39mdestroy()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisconnect\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'disconnect'"
     ]
    }
   ],
   "source": [
    "# Disconnect the client from the carla sim server to cleanly exit simulation\n",
    "\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d607fb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'World' object has no attribute 'kill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bfbd70f8ccaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'World' object has no attribute 'kill'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
